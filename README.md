# ğŸš€ StreamForge: Real-Time E-Commerce Analytics Pipeline

[![Live on GCP](https://img.shields.io/badge/LIVE-GCP%20Deployed-success?style=for-the-badge)](http://35.205.241.21)
[![Flink Dashboard](https://img.shields.io/badge/Flink-Dashboard-orange?style=for-the-badge)](http://35.205.241.21)
[![Kafka](https://img.shields.io/badge/Apache%20Kafka-7.5-red?style=flat-square)](https://kafka.apache.org/)
[![Flink](https://img.shields.io/badge/Apache%20Flink-1.18-blue?style=flat-square)](https://flink.apache.org/)

**A production-grade streaming analytics platform demonstrating expertise in Apache Kafka, Apache Flink, Debezium CDC, PySpark, and Google Cloud Platform.**

---

## ğŸ”´ LIVE DEMO

| Service | URL | Status |
|---------|-----|--------|
| **Flink Dashboard** | [http://35.205.241.21](http://35.205.241.21) | âœ… LIVE |
| **GCP Console** | [console.cloud.google.com](https://console.cloud.google.com/home/dashboard?project=trendstream-portfolio-2026) | âœ… LIVE |
| **BigQuery** | [BigQuery Dataset](https://console.cloud.google.com/bigquery?project=trendstream-portfolio-2026) | âœ… LIVE |

---

## ğŸ¯ Skills Demonstrated

| Technology | Implementation |
|------------|---------------|
| **Apache Kafka** | Confluent 7.5 with Schema Registry (Avro) |
| **Apache Flink (Java)** | Session windows, CEP fraud detection, stateful processing |
| **Apache Flink (Scala)** | CDC event processor with case classes |
| **Debezium CDC** | PostgreSQL WAL capture â†’ Kafka |
| **PySpark** | Daily batch aggregations |
| **GKE + Kubernetes** | Flink on Autopilot with Workload Identity |
| **Terraform** | Full GCP infrastructure as code |
| **BigQuery** | Analytics tables with proper schemas |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              STREAMFORGE ARCHITECTURE                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                        â”‚
â”‚  DATA SOURCES                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Event Producer  â”‚   â”‚ PostgreSQL + Debezium   â”‚   â”‚   Cloud Storage  â”‚            â”‚
â”‚  â”‚    (Python)     â”‚   â”‚        (CDC)            â”‚   â”‚    (Iceberg)     â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â”‚                        â”‚                          â”‚                       â”‚
â”‚           â–¼                        â–¼                          â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    APACHE KAFKA (Confluent 7.5)                                 â”‚  â”‚
â”‚  â”‚  clickstream.events â”‚ transactions.orders â”‚ cdc.public.* â”‚ alerts.fraud         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                        â”‚                          â”‚                       â”‚
â”‚           â–¼                        â–¼                          â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        APACHE FLINK (GKE)            â”‚   â”‚        APACHE SPARK (Batch)        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚Session      â”‚ â”‚Fraud Detector   â”‚ â”‚   â”‚  â”‚ Daily Aggregations (PySpark) â”‚  â”‚  â”‚
â”‚  â”‚  â”‚Aggregator   â”‚ â”‚(CEP Patterns)   â”‚ â”‚   â”‚  â”‚ â€¢ Revenue by category        â”‚  â”‚  â”‚
â”‚  â”‚  â”‚(Java)       â”‚ â”‚(Java)           â”‚ â”‚   â”‚  â”‚ â€¢ Top regions                â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚  â”‚ â€¢ Conversion funnel          â”‚  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚  â”‚Revenue      â”‚ â”‚CDC Processor    â”‚ â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚  â”‚Calculator   â”‚ â”‚(Scala)          â”‚ â”‚                                           â”‚
â”‚  â”‚  â”‚(Java)       â”‚ â”‚                 â”‚ â”‚                                           â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚           â”‚                                                                          â”‚
â”‚           â–¼                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                          DATA SINKS (GCP)                                       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚   BigQuery  â”‚   â”‚   Redis     â”‚   â”‚    GCS      â”‚   â”‚  alerts.fraud       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  Analytics  â”‚   â”‚Feature Storeâ”‚   â”‚  Iceberg    â”‚   â”‚  (Kafka topic)      â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Local Development

```bash
# 1. Start infrastructure (Kafka, Flink, PostgreSQL, Debezium)
docker-compose up -d

# 2. Register Debezium CDC connector
.\cdc\register-connector.ps1

# 3. Build Flink jobs (Java + Scala)
cd flink-jobs && mvn clean package

# 4. Run event producer
cd ../producer && pip install -r requirements.txt
python src/simulator.py --events 1000
```

### Access Points

| Service | Local URL |
|---------|-----------|
| Kafka UI | http://localhost:8080 |
| Flink Dashboard | http://localhost:8082 |
| Schema Registry | http://localhost:8081 |

---

## ğŸ“ Project Structure

```
streamforge/
â”œâ”€â”€ docker-compose.yml          # 12-service local stack
â”œâ”€â”€ producer/                   # Python event simulator (Avro)
â”œâ”€â”€ flink-jobs/                 # Streaming jobs
â”‚   â”œâ”€â”€ src/main/java/          # Java jobs (3)
â”‚   â””â”€â”€ src/main/scala/         # Scala jobs (1)
â”œâ”€â”€ spark/                      # PySpark batch jobs
â”œâ”€â”€ cdc/                        # Debezium CDC configuration
â”‚   â”œâ”€â”€ init-db.sql             # PostgreSQL schema
â”‚   â””â”€â”€ postgres-connector.json # Debezium config
â”œâ”€â”€ k8s/                        # Kubernetes manifests
â”‚   â””â”€â”€ flink-deployment.yaml   # GKE deployment
â””â”€â”€ infrastructure/terraform/   # GCP IaC
```

---

## ğŸ”§ Streaming Jobs

### Flink Jobs (Real-time, <1s latency)

| Job | Language | Purpose | Window Type |
|-----|----------|---------|-------------|
| `SessionAggregator` | Java | User session analytics | Session (30-min gap) |
| `FraudDetector` | Java | CEP fraud pattern matching | Pattern-based |
| `RevenueCalculator` | Java | Real-time revenue metrics | Tumbling (1-min) |
| `CdcEventProcessor` | **Scala** | Process database changes | Continuous |

### Batch Job (PySpark)

| Job | Purpose |
|-----|---------|
| `daily_aggregations.py` | Daily revenue, top regions, conversion funnel |

---

## ğŸ”„ Change Data Capture (Debezium)

Real-time database change capture:

```
PostgreSQL â†’ Debezium â†’ Kafka â†’ Flink
```

**CDC Topics Created:**
- `cdc.public.products` - Price changes, stock updates
- `cdc.public.orders` - Order status transitions
- `cdc.public.order_items` - Line item changes

---

## â˜ï¸ GCP Deployment

Fully deployed to Google Cloud Platform:

| Resource | Details |
|----------|---------|
| **GKE Cluster** | Autopilot, europe-west1 |
| **BigQuery Dataset** | 3 analytics tables |
| **GCS Bucket** | Checkpoints, Iceberg data |
| **Service Account** | Workload Identity enabled |

**Deploy yourself:**
```bash
cd infrastructure/terraform
terraform init && terraform apply
```

---

## ğŸ› ï¸ Challenges Overcome

| Challenge | Solution |
|-----------|----------|
| Windows port conflicts | Remapped Kafka to 29092 |
| Zookeeper healthcheck | Used Confluent's `cub zk-ready` |
| Schema Registry connectivity | Fixed internal Docker networking |
| Terraform IAM race condition | Added explicit `depends_on` |
| GKE auth plugin | Installed gke-gcloud-auth-plugin |

---

## ğŸ“Š Key Patterns Implemented

- **Event-Time Processing** with watermarks for late data
- **Session Windows** for user journey analysis
- **Complex Event Processing (CEP)** for fraud detection
- **Stateful Processing** with RocksDB backend
- **Exactly-Once Semantics** via Flink checkpointing
- **Schema Evolution** with Avro + Schema Registry
- **Change Data Capture** with Debezium

---

## ğŸ‘¨â€ğŸ’» Author

**Kaan Guner** - [GitHub](https://github.com/kaanguner) | [LinkedIn](https://linkedin.com/in/kaanguner)

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE)
